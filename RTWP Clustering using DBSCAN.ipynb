{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8962aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging in to db\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import sklearn.utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#connecting to DB\n",
    "    #>>>cellsConn = pyodbc.connect()\n",
    "\n",
    "#Load data\n",
    "\n",
    "\n",
    "#Getting Cell loads\n",
    " #>>>cellsConn = pyodbc.connect()\n",
    "\n",
    "\n",
    "did=data['did'].values\n",
    "def get_Load_stats(did):        \n",
    "        query1 = '({})'.format(''.join([\"x = '{}' OR \".format(a) for a in did])[:-4])\n",
    "        query = (#>>> SQL Query\n",
    "            .format(query1)\n",
    "                 )\n",
    "        Load_stats =(pd.read_sql(query, cellsConn))\n",
    "        return Load_stats\n",
    "load=get_Load_stats(did)\n",
    "load.drop(['date'],axis=1,inplace=True)\n",
    "data2=data.merge(load, on='did', how='left')\n",
    "\n",
    "#Getting GIDs\n",
    "did=data2['did']\n",
    "def get_Gids(did):        \n",
    "        query1 = '({})'.format(''.join([\"x = '{}' OR \".format(a) for a in did])[:-4])\n",
    "        query = (#>>> SQL Query.format(query1)\n",
    "                 )\n",
    "        Gids =(pd.read_sql(query, cellsConn))\n",
    "        return Gids\n",
    "Gids=get_Gids(did)\n",
    "df=data2.merge(Gids, on='did', how='inner')\n",
    "df['Site_Name']=df['Site_Name'].fillna(df['Cell_name'].str[:-2])\n",
    "\n",
    "#Clustering\n",
    "df.dropna(inplace=True)\n",
    "df['Load status']=df['Overload Flag'].apply(lambda x: 'heavy load' if x>=1 else 'low load')\n",
    "Lamp=df[df['Cell_name'].str.contains('LAMP')]\n",
    "IBS=df[df['Cell_name'].str.contains('IBS')]\n",
    "sites=df[~df['Cell_name'].str.contains('LAMP') & ~df['Cell_name'].str.contains('IBS')]\n",
    "load=sites[sites['Overload Flag']==1]\n",
    "\n",
    "sites=sites[sites['Overload Flag']!=1]\n",
    "\n",
    "U900C1=sites[sites['BAND']=='U900-C1']\n",
    "U900C2=sites[sites['BAND']=='U900-C2']\n",
    "U2100C1=sites[sites['BAND']=='U2100-C1']\n",
    "U2100C2=sites[sites['BAND']=='U2100-C2']\n",
    "\n",
    "sklearn.utils.check_random_state(1000)\n",
    "\n",
    "def get_clusters(X):\n",
    "    Clus_dataSet =X[['LONGITUDE','LATITUDE']]\n",
    "    Clus_dataSet = np.nan_to_num(Clus_dataSet)\n",
    "    \"\"\"The sites must be within 2KM(this could vary from network to network depending on the inter-site distance) \n",
    "    of each other and a cluster must contain at least 5 points\"\"\"\n",
    "    # Compute DBSCAN\n",
    "    epsilon =2/6371.0088\n",
    "    db = DBSCAN(eps=epsilon, min_samples=5, algorithm='ball_tree', metric='haversine').fit(np.radians(Clus_dataSet))\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    X[\"Clus_Db\"]=labels\n",
    "\n",
    "    return(X)\n",
    "\n",
    "get_clusters(U900C1)\n",
    "get_clusters(U900C2)\n",
    "\n",
    "get_clusters(U2100C1)\n",
    "get_clusters(U2100C2)\n",
    "\n",
    "U900C1_clusters=get_clusters(U900C1)\n",
    "U900C2_clusters=get_clusters(U900C2)\n",
    "U2100C1_clusters=get_clusters(U2100C1)\n",
    "U2100C2_clusters=get_clusters(U2100C2)\n",
    "\n",
    "final=U900C1_clusters.append([U900C2_clusters,U2100C1_clusters,U2100C2_clusters])\n",
    "\n",
    "external1=final[final['Clus_Db']>-1]\n",
    "\n",
    "internal1=final[final['Clus_Db']==-1]\n",
    "\n",
    "# internal1['New_column'].head()\n",
    "internal1['New_column']=internal1['Cell_name'].str[-2:].replace({'-4':'-0', '-5':'-1','-6':'-2'})\n",
    "internal1.loc[:,'New_column']=internal1['Site_Name']+ internal1['New_column']\n",
    "\n",
    "ids = internal1[\"New_column\"]\n",
    "maintenance=internal1[ids.isin(ids[ids.duplicated()])]\n",
    "maintenance=maintenance.sort_values('Cell_name', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "def difference(df1, df2, which=None):\n",
    "    \"\"\"Find rows which are different between two DataFrames.\"\"\"\n",
    "    comparison_df = df1.merge(df2,\n",
    "                              indicator=True,\n",
    "                              how='outer')\n",
    "    if which is None:\n",
    "        diff_df = comparison_df[comparison_df['_merge'] != 'both']\n",
    "    else:\n",
    "        diff_df = comparison_df[comparison_df['_merge'] == which]\n",
    "    return diff_df\n",
    "\n",
    "diff_df=difference(internal1,maintenance)\n",
    "Lamp.rename(columns={\"Load status\": \"Status\"}, inplace=True)\n",
    "IBS.rename(columns={\"Load status\": \"Status\"}, inplace=True)\n",
    "load.rename(columns={\"Load status\": \"Status\"}, inplace=True)\n",
    "load['Status']='Overloaded'\n",
    "diff_df['Status']='External'\n",
    "\n",
    "# diff_df.head()\n",
    "maintenance['Status']='Maintenance'\n",
    "\n",
    "external1['Status']='External'\n",
    "\n",
    "#Final dataset\n",
    "Output=diff_df.append([load,maintenance,external1,Lamp,IBS])\n",
    "\n",
    "# Writting to DB\n",
    "conn = pyodbc.connect( #>>> Connect to DB\n",
    "  )\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor=conn.cursor()\n",
    "for index, row in Output.iterrows():\n",
    "    cursor.execute(#>>> Insert Data to the DB           )\n",
    "    conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
